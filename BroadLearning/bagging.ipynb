{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21e8b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\openne\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "# from bls2 import broadnet\n",
    "import bls1,bls3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.dataset import available_data_sets\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,f1_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from random import seed\n",
    "from random import randrange,random\n",
    "from csv import reader\n",
    "import bagging1\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a9bfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Corel5k',\n",
       " 'bibtex',\n",
       " 'birds',\n",
       " 'delicious',\n",
       " 'emotions',\n",
       " 'enron',\n",
       " 'genbase',\n",
       " 'mediamill',\n",
       " 'medical',\n",
       " 'rcv1subset1',\n",
       " 'rcv1subset2',\n",
       " 'rcv1subset3',\n",
       " 'rcv1subset4',\n",
       " 'rcv1subset5',\n",
       " 'scene',\n",
       " 'tmc2007_500',\n",
       " 'yeast'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in available_data_sets().keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2930e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bls = bls3.broadnet(maptimes = 10,\n",
    "               enhencetimes = 10,\n",
    "               map_function = 'tanh',\n",
    "               enhence_function = 'tanh',\n",
    "               batchsize = 'auto',\n",
    "               reg = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856431e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_net=bagging1.bagging_net(10,bls,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127b2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, feature_names, label_names = load_dataset('scene', 'train')\n",
    "X_test, y_test, _, _ = load_dataset('scene', 'test')\n",
    "# X_train=X_train.toarray()\n",
    "# y_train=y_train.toarray()\n",
    "# X_test=X_test.toarray()\n",
    "# y_test=y_test.toarray()\n",
    "# X_train=X_train[:,1:]\n",
    "# X_test=X_test[:,1:]\n",
    "# X_train=pd.DataFrame(X_train.toarray()).drop(0,axis=1)\n",
    "# X_test=pd.DataFrame(X_test.toarray()).drop(0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98a2d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 294) (1211, 6) (1196, 294) (1196, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c6afc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1211x294 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 351805 stored elements in LInked List format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7433ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99995 minvalue -0.99995 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99987 minvalue -0.9999 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99995 minvalue -0.99997 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99984 minvalue -0.99998 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99993 minvalue -0.99994 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99994 minvalue -0.99988 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99988 minvalue -0.99992 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99997 minvalue -0.99995 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99991 minvalue -0.99991 \n",
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99993 minvalue -0.99992 \n",
      "[0.1, 0.12900401139579412, 0.1342319749216301, 0.20114555516854374, 0.14089864158829682, 0.22638387365580728, 0.1208986415882968, 0.157833082954871, 0.1921630094043886, 0.18710868725039723]\n",
      "[0.6290623755500119, 0.8115156986411904, 0.8444028501897025, 1.2653310076565008, 0.8863403418930369, 1.4240957734813586, 0.7605278667830344, 0.9928685410397323, 1.2088251918876396, 1.177030352877791]\n"
     ]
    }
   ],
   "source": [
    "bagging_net.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b53c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.8167671  0.         0.         0.         2.46633377 0.        ]\n",
      " [5.14781069 1.83727139 0.         0.         0.         0.99286854]\n",
      " [6.95397331 0.         0.         1.17703035 7.17610144 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         0.         0.         9.11365966]\n",
      " [2.83737457 0.         1.47346523 0.         2.46633377 3.80995132]\n",
      " [2.15167135 0.         0.99286854 0.         0.84440285 6.40775058]]\n",
      "0.5610367892976589\n",
      "0.10381828316610925\n",
      "0.7159740754860846\n"
     ]
    }
   ],
   "source": [
    "predition=bagging_net.predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e089bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mapping nodes 2940, number of enhence nodes 2940\n",
      "mapping nodes maxvalue 1.0 minvalue -1.0 \n",
      "enhence nodes maxvalue 0.99992 minvalue -0.99998 \n",
      "0.4498327759197324\n",
      "0.12123745819397994\n",
      "0.6116071428571429\n"
     ]
    }
   ],
   "source": [
    "bls.fit(X_train,y_train)\n",
    "predition=bls.predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "677e6e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32525083612040134\n",
      "0.17224080267558528\n",
      "0.5544340302811824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predition=bagging_net.bls_net[0].predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37363d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6053511705685619\n",
      "0.09002229654403568\n",
      "0.7227467811158798\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN,MLTSVM,MLARAM,BRkNNaClassifier\n",
    "classifier = MLkNN()\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predition = classifier.predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d7cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.toarray()\n",
    "y_train=y_train.toarray()\n",
    "X_test=X_test.toarray()\n",
    "y_test=y_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebb4d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5627090301003345\n",
      "0.11970457079152731\n",
      "0.696573648887319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "classifier = MLARAM()\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predition = classifier.predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfa02170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5117056856187291\n",
      "0.15677257525083613\n",
      "0.5678063772570112\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predition = classifier.predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7732bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5225752508361204\n",
      "0.09099777034559643\n",
      "0.6791154791154791\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predition = classifier.predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f3813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a288de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openne] *",
   "language": "python",
   "name": "conda-env-openne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

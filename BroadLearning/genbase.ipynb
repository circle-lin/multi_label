{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d93de44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\openne\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "import bls3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skmultilearn.dataset import load_dataset,load_from_arff\n",
    "from skmultilearn.dataset import available_data_sets\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,f1_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from random import seed\n",
    "from random import randrange,random\n",
    "from csv import reader\n",
    "import bagging1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.adapt import MLkNN,MLTSVM,MLARAM\n",
    "import timeit\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2645fb67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Corel5k',\n",
       " 'bibtex',\n",
       " 'birds',\n",
       " 'delicious',\n",
       " 'emotions',\n",
       " 'enron',\n",
       " 'genbase',\n",
       " 'mediamill',\n",
       " 'medical',\n",
       " 'rcv1subset1',\n",
       " 'rcv1subset2',\n",
       " 'rcv1subset3',\n",
       " 'rcv1subset4',\n",
       " 'rcv1subset5',\n",
       " 'scene',\n",
       " 'tmc2007_500',\n",
       " 'yeast'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in available_data_sets().keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf0fbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 1186)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=load_from_arff(\"E:/IDMdownload/genbase/genbase.arff\",label_count=27,label_location='end')\n",
    "X,y=X.toarray(),y.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2fdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bls = bls3.broadnet(maptimes = 5,\n",
    "               enhencetimes = 5,\n",
    "               map_function = 'sigmoid',\n",
    "               enhence_function = 'sigmoid',\n",
    "               batchsize = 'auto',\n",
    "               reg = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c2cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_net=bagging1.bagging_net(10,bls,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b2c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = MLkNN()\n",
    "ARAM=MLARAM()\n",
    "RFC=RandomForestClassifier()\n",
    "dtc=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f86567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[dtc,RFC,bls,bagging_net,kNN,ARAM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab293ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num用于控制循环的次数\n",
    "num=2\n",
    "accuracy_total=[[]for i in range(len(model))]\n",
    "hamming_total=[[]for i in range(len(model))]\n",
    "f1_micro_total=[[]for i in range(len(model))]\n",
    "f1_macro_total=[[]for i in range(len(model))]\n",
    "time_total=[[]for i in range(len(model))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\openne\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\anaconda3\\envs\\openne\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\anaconda3\\envs\\openne\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\anaconda3\\envs\\openne\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mapping nodes 5930, number of enhence nodes 5930\n",
      "mapping nodes maxvalue 1.0 minvalue 0.0 \n",
      "enhence nodes maxvalue 0.98226 minvalue 0.01986 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\desktop\\Broad-Learning-System\\BroadLearning\\bls3.py:36: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1+np.exp(-data))\n"
     ]
    }
   ],
   "source": [
    "for j in range(num):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "    for i in range(len(model)):\n",
    "        start = timeit.default_timer()\n",
    "        classifier=copy.deepcopy(model[i])\n",
    "        classifier.fit(X_train,y_train)\n",
    "        end = timeit.default_timer()\n",
    "        prediction=classifier.predict(X_test)\n",
    "        accuracy_total[i].append(accuracy_score(y_pred=prediction,y_true=y_test))\n",
    "        hamming_total[i].append(hamming_loss(y_pred=prediction,y_true=y_test))\n",
    "        f1_micro_total[i].append(f1_score(y_pred=prediction,y_true=y_test,average='micro'))\n",
    "        f1_macro_total[i].append(f1_score(y_pred=prediction,y_true=y_test,average='macro'))\n",
    "        time_total[i].append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e418325",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(20,13))\n",
    "plt.subplot(2,3,1)\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(range(1,num+1),accuracy_total[0],color='purple',label='DTC')\n",
    "plt.plot(range(1,num+1),accuracy_total[1],color='yellow',label='RFC')\n",
    "plt.plot(range(1,num+1),accuracy_total[2],color='green',label='bls_base')\n",
    "plt.plot(range(1,num+1),accuracy_total[3],color='red',label='bls_bagging')\n",
    "plt.plot(range(1,num+1),accuracy_total[4],color='orange',label='ML-kNN')\n",
    "plt.plot(range(1,num+1),accuracy_total[5],color='blue',label='ML-ARAM')\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,2)\n",
    "plt.title(\"hamming_loss\")\n",
    "plt.plot(range(1,num+1),hamming_total[0],color='purple',label='DTC')\n",
    "plt.plot(range(1,num+1),hamming_total[1],color='yellow',label='RFC')\n",
    "plt.plot(range(1,num+1),hamming_total[2],color='green',label='bls_base')\n",
    "plt.plot(range(1,num+1),hamming_total[3],color='red',label='bls_bagging')\n",
    "plt.plot(range(1,num+1),hamming_total[4],color='orange',label='ML-kNN')\n",
    "plt.plot(range(1,num+1),hamming_total[5],color='blue',label='ML-ARAM')\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,3)\n",
    "plt.title(\"time\")\n",
    "plt.plot(range(1,num+1),time_total[0],color='purple',label='DTC')\n",
    "plt.plot(range(1,num+1),time_total[1],color='yellow',label='RFC')\n",
    "plt.plot(range(1,num+1),time_total[2],color='green',label='bls_base')\n",
    "plt.plot(range(1,num+1),time_total[3],color='red',label='bls_bagging')\n",
    "plt.plot(range(1,num+1),time_total[4],color='orange',label='ML-kNN')\n",
    "plt.plot(range(1,num+1),time_total[5],color='blue',label='ML-ARAM')\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,4)\n",
    "plt.title(\"F1-macro\")\n",
    "plt.plot(range(1,num+1),f1_macro_total[0],color='purple',label='DTC')\n",
    "plt.plot(range(1,num+1),f1_macro_total[1],color='yellow',label='RFC')\n",
    "plt.plot(range(1,num+1),f1_macro_total[2],color='green',label='bls_base')\n",
    "plt.plot(range(1,num+1),f1_macro_total[3],color='red',label='bls_bagging')\n",
    "plt.plot(range(1,num+1),f1_macro_total[4],color='orange',label='ML-kNN')\n",
    "plt.plot(range(1,num+1),f1_macro_total[5],color='blue',label='ML-ARAM')\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,5)\n",
    "plt.title(\"F1-micro\")\n",
    "plt.plot(range(1,num+1),f1_micro_total[0],color='purple',label='DTC')\n",
    "plt.plot(range(1,num+1),f1_micro_total[1],color='yellow',label='RFC')\n",
    "plt.plot(range(1,num+1),f1_micro_total[2],color='green',label='bls_base')\n",
    "plt.plot(range(1,num+1),f1_micro_total[3],color='red',label='bls_bagging')\n",
    "plt.plot(range(1,num+1),f1_micro_total[4],color='orange',label='ML-kNN')\n",
    "plt.plot(range(1,num+1),f1_micro_total[5],color='blue',label='ML-ARAM')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=[[]for i in range(5)]\n",
    "for i in range(len(model)):\n",
    "    print('the accuracy score of model{0}'.format(i+1),np.mean(accuracy_total[i]))\n",
    "    score[0].append(np.mean(accuracy_total[i]))\n",
    "    print('the hamming loss of model{0}'.format(i+1),np.mean(hamming_total[i]))\n",
    "    score[1].append(np.mean(hamming_total[i]))\n",
    "    print('the time of model{0}'.format(i+1),np.mean(time_total[i]))\n",
    "    score[2].append(np.mean(time_total[i]))\n",
    "    print('the F1 macro score of model{0}'.format(i+1),np.mean(f1_macro_total[i]))\n",
    "    score[3].append(np.mean(f1_macro_total[i]))\n",
    "    print('the F1 micro score of model{0}'.format(i+1),np.mean(f1_micro_total[i]))\n",
    "    score[4].append(np.mean(f1_micro_total[i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f326b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=['dtc','RFC','bls_base','bls_bagging','ML-kNN','ML-ARAM']\n",
    "plt.figure(1,figsize=(20,13))\n",
    "plt.subplot(2,3,1)\n",
    "plt.title(\"accuracy\")\n",
    "plt.bar(model_name,score[0])\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,2)\n",
    "plt.title(\"hamming_loss\")\n",
    "plt.bar(model_name,score[1])\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,3)\n",
    "plt.title(\"time\")\n",
    "plt.bar(model_name,score[2])\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,4)\n",
    "plt.title(\"F1-macro\")\n",
    "plt.bar(model_name,score[3])\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(2,3,5)\n",
    "plt.title(\"F1-micro\")\n",
    "plt.bar(model_name,score[4])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3d012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openne] *",
   "language": "python",
   "name": "conda-env-openne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

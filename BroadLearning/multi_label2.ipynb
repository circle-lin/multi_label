{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e21da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn.metrics as metrics\n",
    "from skmultilearn.dataset import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bagging1\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bcc154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast:train - exists, not redownloading\n",
      "yeast:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, feature_names, label_names = load_dataset('yeast', 'train')\n",
    "X_test, y_test, _, _ = load_dataset('yeast', 'test')\n",
    "X_train=X_train.toarray()\n",
    "y_train=y_train.toarray()\n",
    "X_test=X_test.toarray()\n",
    "y_test=y_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d9cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc=DecisionTreeClassifier()\n",
    "bagging_net=bagging1.bagging_net(20,dtc,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fcc5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11641437536674207, 0.11806041787167557, 0.1182096662992366, 0.10288941850833658, 0.10226539354733813, 0.1327944665621105, 0.1272985850493246, 0.10870993004819543, 0.10243896210814266, 0.10028313864122265, 0.104509800703977, 0.11125890602558944, 0.1, 0.11795474243276885, 0.1325385798366621, 0.1187894722798635, 0.11518746229470725, 0.14282799564325868, 0.10423888740105028, 0.12065843115563482]\n",
      "[1.0134760326105685, 1.0278060895485792, 1.0291054110779128, 0.8957309553818859, 0.8902983415854342, 1.1560772344482577, 1.108231389175894, 0.9464029529302697, 0.8918093884457204, 0.8730412989603815, 0.9098376197330621, 0.9685937352340069, 0.8705763608813765, 1.0268861041581998, 1.1538495451058706, 1.034153064884227, 1.00279481743687, 1.2434267667908923, 0.907479112559299, 1.0504237790512865]\n"
     ]
    }
   ],
   "source": [
    "bagging_net.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0478c768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          3.85528002  7.98531807 ... 18.08736756 17.0532145\n",
      "   0.        ]\n",
      " [ 0.          8.28031252 18.13567531 ... 15.1485121  15.1485121\n",
      "   0.        ]\n",
      " [ 2.27123286 10.15078434 13.81281452 ... 16.33908848 15.18523893\n",
      "   0.        ]\n",
      " ...\n",
      " [ 6.20067328  7.91192219  8.0343486  ... 16.14680233 16.14680233\n",
      "   0.        ]\n",
      " [ 4.20884723  7.12754747  7.75135871 ... 17.27148932 17.27148932\n",
      "   0.        ]\n",
      " [ 7.87242708 12.92716476 10.06079962 ... 17.93610019 16.90699478\n",
      "   0.        ]]\n",
      "0.16030534351145037\n",
      "0.20525003894687646\n",
      "0.6161689730517116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predition=bagging_net.predict(X_test)\n",
    "print(accuracy_score(y_pred=predition,y_true=y_test))\n",
    "print(hamming_loss(y_pred=predition,y_true=y_test))\n",
    "print(f1_score(y_pred=predition,y_true=y_test,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5169c3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\openne\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from bls_addinput import broadnet_enhmap\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4070faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bls = broadnet_enhmap(maptimes = 10, \n",
    "                       enhencetimes = 10,\n",
    "                       traintimes = 10,\n",
    "                       map_function = 'tanh',\n",
    "                       enhence_function = 'sigmoid',\n",
    "                       batchsize = 'auto', \n",
    "                       acc = 1,\n",
    "                       mapstep = 10,\n",
    "                       enhencestep = 10,\n",
    "                       reg = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3b206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf =BinaryRelevance(\n",
    "    classifier=bls,\n",
    "    require_dense=[False, True]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4045eb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=<bls_addinput.broadnet_enhmap object at 0x000001ACBEBA1AC8>,\n",
       "        require_dense=[False, True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train.toarray(),y_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96913d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007633587786259542"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7662a646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d400a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.714\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.71133\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.70667\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.70933\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.71133\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.71\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.706\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.70733\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.70867\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.70533\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.70333\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.62067\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.61\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.612\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.60733\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.602\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.60667\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.59933\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.60867\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.60933\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.61333\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.61667\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.62933\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.62667\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.63067\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.61867\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.618\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.61867\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.62267\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.61867\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.61467\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.62067\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.62067\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.69733\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.69\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.70333\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.696\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.696\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.70267\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.694\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.69333\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.692\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.69267\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.69467\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.722\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.72267\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.72533\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.72533\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.72067\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.72133\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.72667\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.724\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.72467\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.724\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.72133\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.748\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.748\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.748\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.748\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.748\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.748\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.748\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.748\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.748\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.748\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.748\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.826\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.826\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.826\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.826\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.826\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.826\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.82533\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.826\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.826\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.826\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.826\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.80733\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.808\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.80733\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.806\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.80733\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.80733\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.80733\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.80733\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.80733\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.80733\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.80733\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.93467\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.93467\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.93467\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.93467\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.93467\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.93467\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.93467\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.93467\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.93467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.93467\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.93467\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.89267\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.89267\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.89267\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.89267\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.89267\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.89267\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.89267\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.89267\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.89267\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.89267\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.89267\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.868\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.868\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.868\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.868\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.868\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.868\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.868\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.868\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.868\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.868\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.868\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.752\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.752\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.752\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.752\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.752\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.752\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.752\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.752\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.752\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.752\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.752\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.74467\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.744\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.742\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.73933\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.74267\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.74267\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.74467\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.74467\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.744\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.744\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.74533\n",
      "inital setting, number of mapping nodes 10, number of enhence nodes 10, accuracy 0.986\n",
      "enhencing 1, number of mapping nodes 10, number of enhence nodes 15, accuracy 0.986\n",
      "enhencing 2, number of mapping nodes 10, number of enhence nodes 20, accuracy 0.986\n",
      "enhencing 3, number of mapping nodes 10, number of enhence nodes 25, accuracy 0.986\n",
      "enhencing 4, number of mapping nodes 10, number of enhence nodes 30, accuracy 0.986\n",
      "enhencing 5, number of mapping nodes 10, number of enhence nodes 35, accuracy 0.986\n",
      "enhencing 6, number of mapping nodes 10, number of enhence nodes 40, accuracy 0.986\n",
      "enhencing 7, number of mapping nodes 10, number of enhence nodes 45, accuracy 0.986\n",
      "enhencing 8, number of mapping nodes 10, number of enhence nodes 50, accuracy 0.986\n",
      "enhencing 9, number of mapping nodes 10, number of enhence nodes 55, accuracy 0.986\n",
      "enhencing 10, number of mapping nodes 10, number of enhence nodes 60, accuracy 0.986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.056"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bls_enhence import broadnet_enhence\n",
    "bls = broadnet_enhence(maptimes = 10, \n",
    "                       enhencetimes = 10,\n",
    "                       traintimes = 10,\n",
    "                       map_function = 'tanh',\n",
    "                       enhence_function = 'sigmoid',\n",
    "                       batchsize = 1, \n",
    "                       acc = 1,\n",
    "                       step = 5,\n",
    "                       reg = 0.001)\n",
    "clf =BinaryRelevance(\n",
    "    classifier=bls,\n",
    "    require_dense=[False, True]\n",
    ")\n",
    "clf.fit(X_train.toarray(),y_train.toarray())\n",
    "clf.score(X_test,y_test)\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75461efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01145bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064340239912759"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566582ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical:train - does not exists downloading\n",
      "Downloaded medical-train\n",
      "medical:test - does not exists downloading\n",
      "Downloaded medical-test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(333, 1449)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, feature_names, label_names = load_dataset('medical', 'train')\n",
    "X_test, y_test, _, _ = load_dataset('medical', 'test')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535d335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openne] *",
   "language": "python",
   "name": "conda-env-openne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
